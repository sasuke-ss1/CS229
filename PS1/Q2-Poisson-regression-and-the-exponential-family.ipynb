{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs229.stanford.edu/ps/ps1/ps1.pdf\n",
    "\n",
    "Helpful doc on exponential family: http://people.stat.sfu.ca/~raltman/stat402/402L6.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson distribution:\n",
    "\n",
    "\\begin{align*}\n",
    "p(y; \\lambda) &= \\frac{e^{-\\lambda} \\lambda ^y}{y!} \\\\\n",
    "              &= \\frac{e^{-\\lambda} e^{\\ln{\\lambda ^y}}}{y!} \\\\\n",
    "              &= \\frac{e^{-\\lambda} e^{y\\ln{\\lambda}}}{y!} \\\\\n",
    "              &= \\frac{1}{y!}\\mathrm{exp}(y\\ln\\lambda - \\lambda) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the Poisson distribution is in the exponential family with:\n",
    "\n",
    "\\begin{align*}\n",
    "b(y) &= \\frac{1}{y!} \\\\\n",
    "\\eta &= \\ln\\lambda \\iff e^{\\eta}=\\lambda \\\\\n",
    "T(y) &= y \\\\\n",
    "a(\\eta) &= \\lambda = e^{\\eta} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canoical response function:\n",
    "\n",
    "\\begin{align*}\n",
    "g(\\eta) &= \\mathrm{E}[T(y); \\eta] \\\\\n",
    "        &= \\mathrm{E}[y; \\eta] \\\\\n",
    "        &= \\lambda \\\\\n",
    "        &= e^{\\eta} \\\\\n",
    "        &= e^{\\theta^T x} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're dealing with stochastic (vs batch) gradient ascent, then we want to compute the derivative of the log-likelihood of a single training example.\n",
    "\n",
    "Log-likelihood:\n",
    "\n",
    "\\begin{align*}\n",
    "\\ell(\\theta) &= \\mathrm{log} (p(y^{(i)}|x^{(i)}; \\theta)) \\\\\n",
    "          &= \\mathrm{log} \\Big[\\frac{1}{y^{(i)}!}\\mathrm{exp}(y^{(i)}\\ln\\theta - \\theta)\\Big] \\\\\n",
    "          &= \\mathrm{log} \\Big(\\frac{1}{y^{(i)}!}\\Big) + \\mathrm{log} \\Big[\\mathrm{exp}(y^{(i)}\\ln\\theta - \\theta)\\Big] \\\\\n",
    "          &= \\mathrm{log} \\frac{1}{y^{(i)}!} + y^{(i)} \\mathrm{ln} \\theta - \\theta \\\\\n",
    "          &= \\mathrm{log} \\frac{1}{y^{(i)}!} + y^{(i)} \\eta - e^{\\eta} \\\\\n",
    "          &= \\mathrm{log} \\frac{1}{y^{(i)}!} + y^{(i)} \\theta^T x^{(i)} - e^{\\theta^T x^{(i)}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Its derivative:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_j} &= y^{(i)} x_j^{(i)} - e^{\\theta^T x} x_j^{(i)} \\\\\n",
    "                                             &= (y^{(i)} - e^{\\theta^T x}) x_j^{(i)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So the stochastic gradient ascent rule:\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta_j &:= \\theta_j + \\alpha\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_j} = \\theta_j + \\alpha(y^{(i)} - e^{\\theta^T x^{(i)}})x_j^{(i)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, since we're dealing with stochastic (vs batch) gradient ascent, then we want to compute the derivative of the log-likelihood of a single training example.\n",
    "\n",
    "GLM:\n",
    "\n",
    "$$p(y|x;\\eta) = b(y) e^{\\eta^TT(y) - a(\\eta)} = b(y) e^{\\eta^Ty - a(\\eta)} $$\n",
    "\n",
    "where the last equality follows from $T(y) = y$. And the log-likelihood is \n",
    "\n",
    "\\begin{align*}\n",
    "\\ell(\\theta)=\\mathrm{log}(p(y|x;\\eta)) = \\mathrm{log}\\big[b(y) e^{\\eta^T y - a(\\eta)}\\big] = \\mathrm{log}(b(y)) + \\eta^T y - a(\\eta)\n",
    "\\end{align*}\n",
    "\n",
    "The partial derivatives are\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_j}=\\frac{\\partial \\mathrm{log}(p(y|x;\\eta))}{\\partial \\theta_j} \n",
    "     = 0 + y \\frac{\\partial \\eta^T}{\\theta_j} - \\frac{\\partial a(\\eta)}{\\partial \\eta} \\frac{\\partial \\eta}{\\theta_j}\n",
    "     = y x_j  - \\frac{\\partial a(\\eta)}{\\partial \\eta} x_j\n",
    "     = \\Big(y - \\frac{\\partial a(\\eta)}{\\partial \\eta}\\Big) x_j \\tag{1}\n",
    "$$\n",
    "\n",
    "So we want to compute $\\frac{\\partial a(\\eta)}{\\partial \\eta}$. Note that $p(y|x;\\eta)$ is a PDF. Like any PDF, it integrates to 1:\n",
    "\n",
    "$$ 1=\\int_{y}p(y|x;\\eta) dy=\\int_{y}b(y) e^{\\eta^Ty - a(\\eta)} dy=e^{-a(\\eta)}\\int_{y}b(y) e^{\\eta^Ty} dy $$\n",
    "\n",
    "which implies that\n",
    "\n",
    "$$ e^{a(\\eta)}=\\int_{y}b(y) e^{\\eta^Ty} dy $$\n",
    "\n",
    "Differentiating both sides with respect to $\\eta$, we get\n",
    "\n",
    "$$ e^{a(\\eta)}\\frac{\\partial a(\\eta)}{\\partial\\eta}=\\frac{\\partial}{\\partial\\eta}\\int_{y}b(y) e^{\\eta^Ty} dy=\\int_{y}\\frac{\\partial}{\\partial\\eta}b(y) e^{\\eta^Ty} dy=\\int_{y}b(y)\\cdot y\\cdot e^{\\eta^Ty} dy $$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$ \\frac{\\partial a(\\eta)}{\\partial\\eta}=\\int_{y}b(y)\\cdot y\\cdot e^{\\eta^Ty-a(\\eta)} dy=\\int_{y}y\\cdot p(y|x;\\eta) dy = E[y|x;\\eta]=h(x) $$\n",
    "\n",
    "The last equality follows from the definition of the canonical response function on p.26 of the notes-1. Then (1) becomes\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_j}=\\Big(y - \\frac{\\partial a(\\eta)}{\\partial \\eta}\\Big) x_j=(y-h(x))x_j\n",
    "\\end{align*}\n",
    "\n",
    "So the stochastic gradient ascent rule is\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta_j &:= \\theta_j + \\alpha\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_j} = \\theta_j + \\alpha(y - h(x))x_j = \\theta_j - \\alpha(h(x)-y)x_j\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very interesting to know that all GLM where $T(y) = y$ have the same update rule for stochastic gradient ascent."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
