{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=(10000, 784)  y=(10000, 10)  num_train=8000  img_size=784  num_class=10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "X = np.ndfromtxt('images.csv', delimiter=',')\n",
    "y_orig = np.ndfromtxt(\"labels.csv\", delimiter=',', dtype=np.int8)\n",
    "img_size = X.shape[1]\n",
    "num_class = 10\n",
    "y = np.zeros([len(y_orig), num_class])\n",
    "y[np.arange(len(y_orig)), y_orig] = 1\n",
    "num_train = int(len(y) * 0.8)\n",
    "print(\"X={}  y={}  num_train={}  img_size={}  num_class={}\".format(X.shape,y.shape,num_train,img_size,num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train=(8000, 784)  y_train=(8000, 10)  X_test=(1999, 784)  y_test=(1999, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[0:num_train, :]\n",
    "X_test = X[num_train:-1,:]\n",
    "y_train = y[0:num_train]\n",
    "y_test = y[num_train:-1]\n",
    "print(\"X_train={}  y_train={}  X_test={}  y_test={}\".format(X_train.shape,y_train.shape,X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta.T=(10, 784)  X[i,:]=(784,)  tempw=(10,)  npamax=0.0  tempwn=(10,)\n",
      "183 ms ± 1.47 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def h_elementwise(theta, X):\n",
    "    # phi=(10000, 10)\n",
    "    phi = np.zeros([X.shape[0], theta.shape[1]])\n",
    "    for i in range(X.shape[0]):\n",
    "        # theta.T=(10, 784)  X[i,:]=(784,)  temp.shape=(10,)\n",
    "        temp = np.matmul(np.transpose(theta), X[i, :])\n",
    "        # np.amax(temp).shape = ()\n",
    "        temp = temp - np.amax(temp)\n",
    "        # temp=(10,)  temp2.shape=(10,)\n",
    "        temp2 = np.exp(temp)\n",
    "        phi[i, :] = temp2 / np.sum(temp2)\n",
    "    return(phi)\n",
    "\n",
    "theta = np.zeros([img_size, num_class])\n",
    "tempw = np.matmul(np.transpose(theta), X[0, :])\n",
    "npamax = np.amax(tempw)\n",
    "tempwn = tempw - np.amax(tempw)\n",
    "print(\"theta.T={}  X[i,:]={}  tempw={}  npamax={}  tempwn={}\".format(theta.T.shape, X[0, :].shape, tempw.shape, npamax, tempwn.shape))\n",
    "\n",
    "%timeit h_elementwise(theta, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.67 ms ± 53.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def h_vec(theta, X):\n",
    "    # X=(10000, 784)  theta.shape=(784, 10)  eta=(10000, 10)\n",
    "    eta = np.matmul(X, theta)\n",
    "    temp = np.exp(eta - np.reshape(np.amax(eta, axis=1), [-1, 1]))\n",
    "    # npamaxrs=(10000, 1)  temp=(10000, 10)  npsum=(10000,)  npsumrs=(10000, 1)\n",
    "#    print(\"eta={}  npamaxrs={}  temp={}  npsum={}  npsumrs={}\".format(eta.shape, (np.reshape(np.amax(eta, axis=1),\\\n",
    "#        [-1, 1])).shape, temp.shape, (np.sum(temp, axis=1)).shape, (np.reshape(np.sum(temp, axis=1), [-1, 1])).shape))\n",
    "    return (temp / np.reshape(np.sum(temp, axis=1), [-1, 1]))\n",
    "\n",
    "%timeit h_vec(theta, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With softmax as the activation function, for each observation $k$, we assign probabilities $p(y_j^{(k)}|x^{(k)})\\equiv h_{j}^{(k)}$ for each class $j$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(y_j^{(k)}|x^{(k)})\\equiv h_{j}^{(k)}\\equiv\\frac{e^{\\theta_j^Tx^{(k)}}}{\\sum_{q=1}^{10}e^{\\theta_q^Tx^{(k)}}}\n",
    "\\end{align*}$$\n",
    "\n",
    "Notice that $\\theta$ is matrix with $n=784$ rows and $c=10$ columns.\n",
    "\n",
    "Now we implement gradient descent, which was derived in the class notes 1, p.5:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\theta_{i,j}\\mapsto\\theta_{i,j}-\\alpha\\sum_{k=1}^m(h_{j}^{(k)}-y_j^{(k)})x_i^{(k)}\n",
    "\\tag{sftmx.1}\n",
    "\\end{align*}$$\n",
    "\n",
    "Define\n",
    "\n",
    "$$\\begin{align*}\n",
    "h_\\theta(x^{(k)})=\\begin{bmatrix}\\frac{e^{\\theta_1^Tx^{(k)}}}{\\sum_{q=1}^{10}e^{\\theta_q^Tx^{(k)}}}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(k)}}}{\\sum_{q=1}^{10}e^{\\theta_q^Tx^{(k)}}}\\end{bmatrix}\\quad y^{(k)}=\\begin{bmatrix}0&\\dots&1&\\dots&0\\end{bmatrix}\n",
    "\\end{align*}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{align*}\n",
    "h_\\theta(X)=\\begin{bmatrix}h_\\theta(x^{(1)})\\\\\\vdots\\\\h_\\theta(x^{(m)})\\end{bmatrix}=\\begin{bmatrix}\\frac{e^{\\theta_1^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}\\\\\\vdots&\\ddots&\\vdots\\\\\\frac{e^{\\theta_1^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}\\end{bmatrix}\\quad Y=\\begin{bmatrix}y^{(1)}\\\\\\vdots\\\\y^{(m)}\\end{bmatrix}=\\begin{bmatrix}0&\\dots&1&\\dots&0\\\\\\vdots&\\ddots&\\vdots&\\ddots&\\vdots\\\\0&\\dots&1&\\dots&0\\end{bmatrix}\n",
    "\\end{align*}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{align*}\n",
    "D&=h_\\theta(X)-Y=\\begin{bmatrix}h_\\theta(x^{(1)})-y^{(1)}\\\\\\vdots\\\\h_\\theta(x^{(m)})-y^{(m)}\\end{bmatrix}=\\begin{bmatrix}\\frac{e^{\\theta_1^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}-y_1^{(1)}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}-y_{10}^{(1)}\\\\\\vdots&\\ddots&\\vdots\\\\\\frac{e^{\\theta_1^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}-y_{1}^{(m)}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}-y_{10}^{(m)}\\end{bmatrix}=\\begin{bmatrix}h_{1}^{(1)}-y_1^{(1)}&\\dots& h_{10}^{(1)}-y_{10}^{(1)}\\\\\\vdots&\\ddots&\\vdots\\\\h_{1}^{(m)}-y_{1}^{(m)}&\\dots& h_{10}^{(m)}-y_{10}^{(m)}\\end{bmatrix}\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\\begin{align*}\n",
    "X^TD&=\\begin{bmatrix}x_{1}^{(1)}&\\dots&x_{1}^{(m)}\\\\\\vdots&\\ddots&\\vdots\\\\x_{n}^{(1)}&\\dots&x_{n}^{(m)}\\end{bmatrix}\\begin{bmatrix}\\frac{e^{\\theta_1^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}-y_1^{(1)}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(1)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(1)}}}-y_{10}^{(1)}\\\\\\vdots&\\ddots&\\vdots\\\\\\frac{e^{\\theta_1^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}-y_{1}^{(m)}&\\dots& \\frac{e^{\\theta_{10}^Tx^{(m)}}}{\\sum_{k=1}^{10}e^{\\theta_k^Tx^{(m)}}}-y_{10}^{(m)}\\end{bmatrix}\\\\\n",
    "    &=\\begin{bmatrix}x_{1}^{(1)}&\\dots&x_{1}^{(m)}\\\\\\vdots&\\ddots&\\vdots\\\\x_{n}^{(1)}&\\dots&x_{n}^{(m)}\\end{bmatrix}_{n\\times m}\\begin{bmatrix}h_{1}^{(1)}-y_1^{(1)}&\\dots& h_{10}^{(1)}-y_{10}^{(1)}\\\\\\vdots&\\ddots&\\vdots\\\\h_{1}^{(m)}-y_{1}^{(m)}&\\dots& h_{10}^{(m)}-y_{10}^{(m)}\\end{bmatrix}_{m\\times 10}\\\\\n",
    "    &=\\begin{bmatrix}\\sum_{k=1}^{m}(h_{1}^{(k)}-y_1^{(k)})x_{1}^{(k)}&\\dots&\\sum_{k=1}^{m}(h_{10}^{(k)}-y_{10}^{(k)})x_{1}^{(k)}\\\\\\vdots&\\ddots&\\vdots\\\\\\sum_{k=1}^{m}(h_{1}^{(k)}-y_1^{(k)})x_{n}^{(k)}&\\dots&\\sum_{k=1}^{m}(h_{10}^{(k)}-y_{10}^{(k)})x_{n}^{(k)}\\end{bmatrix}_{n\\times 10}\n",
    "\\end{align*}$$\n",
    "\n",
    "Then to update $\\theta{i,j}$ for all $i,j$ as in sftmx.1, we have\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\theta\\mapsto\\theta-\\alpha X^TD\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.05970191955566406 seconds   theta=(784, 10)  X_test=(1999, 784)\n",
      "percentage correct: 0.33016508254127064\n"
     ]
    }
   ],
   "source": [
    "# not fully vectorized\n",
    "def GD(theta, X_train, y_train, alpha):\n",
    "    # X_train=(8000, 784)  theta=(784,10)  diff=(8000,10)  y_train=(8000, 10)\n",
    "    diff = h_vec(theta, X_train) - y_train\n",
    "    #print(\"X_train={}  theta={}  diff={} y_train={}\".format(X_train.shape, theta.shape, diff.shape, y_train.shape))\n",
    "    for k in range(num_class):\n",
    "        # diffT=(1,8000)  w=(1,784)\n",
    "        diffT = np.reshape(diff[:, k], [1, -1])\n",
    "        w = np.matmul(diffT, X_train)\n",
    "        #if k==0: print(\"diffT={}  w={}\".format(diffT.shape, w.shape))\n",
    "        theta[:, k] -= alpha * np.squeeze(w)\n",
    "        \n",
    "def train(X_train, y_train, max_iter, alpha):\n",
    "    theta = np.zeros([img_size, 10])\n",
    "    for i in range(max_iter):\n",
    "        GD(theta, X_train, y_train, alpha)       \n",
    "    return theta\n",
    "\n",
    "max_iter = 2\n",
    "alpha = 0.001\n",
    "start = time.time()\n",
    "theta = train(X_train, y_train, max_iter, alpha)\n",
    "end = time.time()\n",
    "print(\"time elapsed: {} seconds   theta={}  X_test={}\".format(end - start, theta.shape, X_test.shape))\n",
    "pred = np.argmax(h_vec(theta, X_test), axis=1)\n",
    "print(\"percentage correct: {0}\".format(np.sum(pred == np.argmax(y_test, axis=1)) / float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 1.0092706680297852 seconds\n",
      "percentage correct: 0.9259629814907454\n"
     ]
    }
   ],
   "source": [
    "#full vectorized\n",
    "def GD_vec(theta, X_train, y_train, alpha):\n",
    "    theta -= alpha * np.matmul(np.transpose(X_train), (h_vec(theta, X_train) - y_train))\n",
    "    \n",
    "def train_vec(X_train, y_train, max_iter, alpha):\n",
    "    theta = np.zeros([img_size, 10])\n",
    "    for i in range(max_iter):\n",
    "        GD_vec(theta, X_train, y_train, alpha)       \n",
    "    return theta\n",
    "\n",
    "max_iter = 100\n",
    "alpha = 0.001\n",
    "start = time.time()\n",
    "theta = train_vec(X_train, y_train, max_iter, alpha)\n",
    "end = time.time()\n",
    "print(\"time elapsed: {0} seconds\".format(end - start))\n",
    "pred = np.argmax(h_vec(theta, X_test), axis=1)\n",
    "print(\"percentage correct: {0}\".format(np.sum(pred == np.argmax(y_test, axis=1)) / float(len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
