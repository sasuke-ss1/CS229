{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs229.stanford.edu/ps/ps1/ps1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gaussian Discriminant Analysis (GDA), we wish to show that the posterior distribution of a label given an observation takes the form of logistic regression. That is, we wish to show that\n",
    "\n",
    "$$p(y\\mid x;\\phi,\\mu_{-1},\\mu_1\\Sigma) = \\frac{1}{1 + e^{-y(\\theta^T x + \\theta_0)}}$$\n",
    "\n",
    "where $\\theta\\in\\mathbb{R}^n$ and the bias term $\\theta_0$ are some appropriate functions of $\\phi,\\mu_{-1},\\mu_1\\Sigma$.\n",
    "\n",
    "It is very interesting that GDA, a generative model with the strong modeling assumption that $p(x\\mid y)$ is multivariate Gaussian, can be expressed as logistic regression, a discriminative model. Please see the cs229 class-notes-2 for details and discussion.\n",
    "\n",
    "Given \n",
    "\n",
    "$$\\begin{align*} \n",
    "p(y) &= \\begin{cases}\n",
    "  \\phi          & \\text{if} \\; y = 1 \\\\\n",
    "  1 - \\phi     & \\text{if} \\; y = -1\n",
    "\\end{cases} \\\\\n",
    "p(x\\mid y=1) &= \\frac{1}{(2\\pi)^{n/2} \\lvert \\Sigma\\rvert^{1/2}} \\mathrm{exp}\\bigg(-\\frac{1}{2}(x - \\mu_{1})^T \\Sigma^{-1} (x - \\mu_{1}) \\bigg) \\\\\n",
    "p(x\\mid y=-1) &= \\frac{1}{(2\\pi)^{n/2} \\lvert \\Sigma\\rvert^{1/2}} \\mathrm{exp}\\bigg(-\\frac{1}{2}(x - \\mu_{-1})^T \\Sigma^{-1} (x - \\mu_{-1}) \\bigg) \\\\\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define\n",
    "\n",
    "$$\\begin{align*}\n",
    "A &\\equiv -\\frac{1}{2}(x - \\mu_{1})^T \\Sigma^{-1} (x - \\mu_{1}) \\\\\n",
    "B &\\equiv -\\frac{1}{2}(x - \\mu_{-1})^T \\Sigma^{-1} (x - \\mu_{-1}) \\\\\n",
    "C &\\equiv \\frac{1}{(2\\pi)^{n/2} \\lvert \\Sigma\\rvert^{1/2}}\n",
    "\\end{align*}$$\n",
    "\n",
    "so that\n",
    "\n",
    "$$\\begin{align*} \n",
    "p(x\\mid y=1)  &= C e^A \\\\\n",
    "p(x\\mid y=-1) &= C e^B \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes formula gives\n",
    "\n",
    "$$\\begin{align*} \n",
    "p(y=1\\mid x) &= \\frac{p(x\\mid y=1) p(y=1)}{p(x\\mid y=1) p(y=1) + p(x\\mid y=-1) p(y=-1)} \\\\\n",
    "           &= \\frac{Ce^A \\phi}{Ce^A \\phi + Ce^B (1 - \\phi)} \\\\\n",
    "           &= \\frac{e^A \\phi}{e^A \\phi + e^B (1 - \\phi)} \\\\\n",
    "           &= \\frac{1}{1 + \\frac{1 - \\phi}{\\phi} e^{B - A}} \\\\\n",
    "           &= \\frac{1}{1 + e^{(B - A + \\mathrm{ln}(1 - \\phi) - \\mathrm{ln}\\phi)}} \\\\\n",
    "           &= \\frac{1}{1 + e^{- 1 (A -B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}} \\\\\n",
    "           &= \\frac{1}{1 + e^{- y (A -B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}} \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly for $y = -1$:\n",
    "\n",
    "$$\\begin{align*} \n",
    "p(y=-1\\mid x) &= \\frac{p(x\\mid y=-1) p(y=-1)}{p(x\\mid y=1) p(y=1) + p(x\\mid y=-1) p(y=-1)} \\\\\n",
    "           &= \\frac{Ce^B (1 - \\phi)}{Ce^A \\phi + Ce^B (1 - \\phi)} \\\\\n",
    "           &= \\frac{1}{\\frac{\\phi}{1 - \\phi} e^{A - B} + 1} \\\\\n",
    "           &= \\frac{1}{1 + e^{(A - B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}} \\\\\n",
    "           &= \\frac{1}{1 + e^{- y (A - B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}} \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in both cases,\n",
    "\n",
    "$$p(y\\mid x) = \\frac{1}{1 + e^{- y (A - B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}}\\tag{1}$$\n",
    "\n",
    "Note that\n",
    "\n",
    "$$\\begin{align*}\n",
    "A-B &= -\\frac{1}{2}(x - \\mu_{1})^T \\Sigma^{-1} (x - \\mu_{1}) + \\frac{1}{2}(x - \\mu_{-1})^T \\Sigma^{-1} (x - \\mu_{-1})\\\\\n",
    "                    &= -\\frac{1}{2}\\big[x^T\\Sigma^{-1}x-x^T\\Sigma^{-1}\\mu_1-\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\big(x^T\\Sigma^{-1}x-x^T\\Sigma^{-1}\\mu_{-1}-\\mu_{-1}^T\\Sigma^{-1}x+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big)\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[-x^T\\Sigma^{-1}\\mu_1-\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\big(-x^T\\Sigma^{-1}\\mu_{-1}-\\mu_{-1}^T\\Sigma^{-1}x+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big)\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[-(x^T\\Sigma^{-1}\\mu_1)^T-\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\big(-(x^T\\Sigma^{-1}\\mu_{-1})^T-\\mu_{-1}^T\\Sigma^{-1}x+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big)\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[-\\mu_1^T\\Sigma^{-1}x-\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\big(-\\mu_{-1}^T\\Sigma^{-1}x-\\mu_{-1}^T\\Sigma^{-1}x+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big)\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[-2\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\big(-2\\mu_{-1}^T\\Sigma^{-1}x+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big)\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[-2\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1+2\\mu_{-1}^T\\Sigma^{-1}x-\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[2\\mu_{-1}^T\\Sigma^{-1}x-2\\mu_1^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]  \\\\\n",
    "                    &= -\\frac{1}{2}\\big[2(\\mu_{-1}-\\mu_1)^T\\Sigma^{-1}x+\\mu_1^T\\Sigma^{-1}\\mu_1-\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]  \\\\\n",
    "                    &= (\\mu_1-\\mu_{-1})^T\\Sigma^{-1}x+\\frac{1}{2}\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_1^T\\Sigma^{-1}\\mu_1  \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Define\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\theta &\\equiv \\Sigma^{-1}(\\mu_1-\\mu_{-1}) \\\\\n",
    "\\theta_0 &\\equiv \\frac{1}{2}\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_1^T\\Sigma^{-1}\\mu_1 - \\mathrm{ln}\\Big(\\frac{1 - \\phi}{\\phi}\\Big) \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "So \n",
    "\n",
    "$$\\begin{align*}\n",
    "\\theta^Tx + \\theta_0 &= \\big(\\Sigma^{-1}(\\mu_1-\\mu_{-1})\\big)^Tx + \\frac{1}{2}\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_1^T\\Sigma^{-1}\\mu_1 - \\mathrm{ln}\\Big(\\frac{1 - \\phi}{\\phi}\\Big) \\\\\n",
    "                    &= (\\mu_1-\\mu_{-1})^T\\Sigma^{-1}x + \\frac{1}{2}\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_1^T\\Sigma^{-1}\\mu_1 + \\mathrm{ln}\\Big(\\frac{\\phi}{1 - \\phi}\\Big) \\\\\n",
    "                    &= A - B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi)  \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "And (1) becomes\n",
    "\n",
    "$$p(y\\mid x) = \\frac{1}{1 + e^{- y (A - B + \\mathrm{ln}\\phi - \\mathrm{ln}(1 - \\phi))}} = \\frac{1}{1 + e^{-y(\\theta^T x + \\theta_0)}}$$\n",
    "\n",
    "which is in the form of the logistic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)\n",
    "\n",
    "We will handle this in part (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that\n",
    "\n",
    "$$\\begin{align*} \n",
    "p(y) &= \\begin{cases}\n",
    "  \\phi          & \\text{if} \\; y = 1 \\\\\n",
    "  1 - \\phi     & \\text{if} \\; y = -1\n",
    "\\end{cases} \\\\\\\\\n",
    "   &=\\phi^{1\\{y=1\\}}(1-\\phi)^{1\\{y=-1\\}}\n",
    "\\end{align*}$$\n",
    "\n",
    "And the $\\ln$ of this is\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\ln(p(y))&=\\ln(\\phi^{1\\{y=1\\}}(1-\\phi)^{1\\{y=-1\\}})\\\\\n",
    "    &=\\ln(\\phi^{1\\{y=1\\}}) + \\ln((1-\\phi)^{1\\{y=-1\\}})\\\\\n",
    "    &={1\\{y=1\\}}\\ln(\\phi) + {1\\{y=-1\\}}\\ln((1-\\phi))\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence the log-likelihood is\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\ell(\\phi,\\mu_{-1},\\mu_1,\\Sigma) &= \\mathrm{ln}\\prod_{i=1}^mp(x^{(i)},y^{(i)};\\phi,\\mu_{-1},\\mu_1\\Sigma) \\\\\n",
    "     &= \\mathrm{ln}\\prod_{i=1}^mp(x^{(i)}\\mid y^{(i)};\\phi,\\mu_{-1},\\mu_1,\\Sigma) p(y^{(i)};\\phi)\\\\\n",
    "     &= \\sum_{i=1}^m\\mathrm{ln}p(x^{(i)}\\mid y^{(i)};\\phi,\\mu_{-1},\\mu_1,\\Sigma)+ \\sum_{i=1}^m\\mathrm{ln}p(y^{(i)};\\phi)\\\\\n",
    "     &\\approxeq \\sum_{i=1}^m\\big[\\frac{1}{2}\\mathrm{ln}\\frac{1}{\\lvert\\Sigma\\rvert}-\\frac{1}{2}(x^{(i)}-\\mu_{y^{(i)}})^T\\Sigma^{-1}(x^{(i)}-\\mu_{y^{(i)}})+{1\\{y^{(i)}=1\\}}\\ln(\\phi) + {1\\{y^{(i)}=-1\\}}\\ln(1-\\phi)\\big]\\tag{2}\n",
    "\\end{align*}$$\n",
    "\n",
    "In the last quasi-equality, we have discarded the term $\\ln\\big(\\frac{1}{(2\\pi)^{n/2}}\\big)$ since this is irrelevant to determining maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maximize the log-likelihood in $\\phi$, let's compute the partial derivative of (2) with respect to $\\phi$ and set it equal to zero:\n",
    "\n",
    "$$\\begin{align*} \n",
    "0=\\frac{\\partial\\ell}{\\partial\\phi} &= \\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\\frac1{\\phi} - \\sum_{i=1}^m{1\\{y^{(i)}=-1\\}}\\frac1{1-\\phi}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\sum_{i=1}^m{1\\{y^{(i)}=-1\\}}\\frac1{1-\\phi} = \\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\\frac1{\\phi}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Or\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\frac1{1-\\phi}\\sum_{i=1}^m{1\\{y^{(i)}=-1\\}} = \\frac1{\\phi}\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Multiplying both sides by $\\phi(1-\\phi)$, we get\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\phi\\sum_{i=1}^m{1\\{y^{(i)}=-1\\}} &= (1-\\phi)\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\\\\\n",
    "    &= \\sum_{i=1}^m{1\\{y^{(i)}=1\\}} - \\phi\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\sum_{i=1}^m{1\\{y^{(i)}=1\\}} &= \\phi\\sum_{i=1}^m{1\\{y^{(i)}=-1\\}} + \\phi\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\\\\\n",
    "    &= \\phi\\sum_{i=1}^m\\big[1\\{y^{(i)}=-1\\} + 1\\{y^{(i)}=1\\}\\big]\\\\\n",
    "    &= \\phi\\sum_{i=1}^m1\\\\\n",
    "    &= \\phi m\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\phi = \\frac1m\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Now let's compute the gradient of (2) with respect to $\\mu_{-1}$:\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_{\\mu_{-1}}\\ell &= -\\frac{1}{2}\\sum_{i=1}^m\\nabla_{\\mu_{-1}}(x^{(i)}-\\mu_{y^{(i)}})^T\\Sigma^{-1}(x^{(i)}-\\mu_{y^{(i)}})\\\\ \n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}(x^{(i)}-\\mu_{-1})^T\\Sigma^{-1}(x^{(i)}-\\mu_{-1})\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[x^{(i)^T}\\Sigma^{-1}x^{(i)}-x^{(i)^T}\\Sigma^{-1}\\mu_{-1}-\\mu_{-1}^T\\Sigma^{-1}x^{(i)}+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[-x^{(i)^T}\\Sigma^{-1}\\mu_{-1}-\\mu_{-1}^T\\Sigma^{-1}x^{(i)}+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[-(x^{(i)^T}\\Sigma^{-1}\\mu_{-1})^T-\\mu_{-1}^T\\Sigma^{-1}x^{(i)}+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[-\\mu_{-1}^T\\Sigma^{-1}x^{(i)}-\\mu_{-1}^T\\Sigma^{-1}x^{(i)}+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[-2\\mu_{-1}^T\\Sigma^{-1}x^{(i)}+\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}\\big[\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-2\\mu_{-1}^T\\Sigma^{-1}x^{(i)}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\nabla_{\\mu_{-1}}tr\\big[\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-2\\mu_{-1}^T\\Sigma^{-1}x^{(i)}\\big]\\\\\n",
    "    &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}\\big[\\nabla_{\\mu_{-1}}tr(\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1})-2\\nabla_{\\mu_{-1}}tr(\\mu_{-1}^T\\Sigma^{-1}x^{(i)})\\big]\\tag{3}\n",
    "\\end{align*}$$\n",
    "\n",
    "The fifth equality follows because $r^T=r$ for all $r\\in\\mathbb{R}$. The next-to-last equality follows because $tr(r)=r$ for all $r\\in\\mathbb{R}$. The last equality follows because the trace and gradient operators are both linear.\n",
    "\n",
    "Note that\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_{\\mu_{-1}}tr(\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}) &= \\nabla_{(\\mu_{-1}^T)^T}tr(\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}) \\\\\n",
    "    &= \\big[\\nabla_{\\mu_{-1}^T}tr(\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}I)\\big]^T \\\\\n",
    "    &= \\big[I\\mu_{-1}^T\\Sigma^{-1}+I\\mu_{-1}^T\\Sigma^{-T}\\big]^T \\\\\n",
    "    &= \\big[\\mu_{-1}^T\\Sigma^{-1}+\\mu_{-1}^T\\Sigma^{-T}\\big]^T \\\\\n",
    "    &= \\big[\\mu_{-1}^T\\Sigma^{-T}+\\mu_{-1}^T\\Sigma^{-T}\\big]^T \\\\\n",
    "    &= 2\\big[\\mu_{-1}^T\\Sigma^{-T}\\big]^T \\\\\n",
    "    &= 2\\Sigma^{-1}\\mu_{-1} \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "The second equality follows from cs229-notes1, p.9, eq.2 ($I=1\\in\\mathbb{R}$) and the third equality follows from eq.3.\n",
    "\n",
    "Also note that\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_{\\mu_{-1}}tr(\\mu_{-1}^T\\Sigma^{-1}x^{(i)}) &= \\nabla_{(\\mu_{-1}^T)^T}tr(\\mu_{-1}^T\\Sigma^{-1}x^{(i)}) \\\\\n",
    "    &= \\big[\\nabla_{\\mu_{-1}^T}tr(\\mu_{-1}^T\\Sigma^{-1}x^{(i)})\\big]^T \\\\\n",
    "    &= \\big[(\\Sigma^{-1}x^{(i)})^T\\big]^T \\\\\n",
    "    &= \\Sigma^{-1}x^{(i)} \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Hence (3) becomes\n",
    "\n",
    "$$\\begin{align*} \n",
    "0 = \\nabla_{\\mu_{-1}}\\ell &= -\\frac{1}{2}\\sum_{i:y^{(i)}=-1}[2\\Sigma^{-1}\\mu_{-1}-2\\Sigma^{-1}x^{(i)}] \\\\\n",
    "    &= \\sum_{i:y^{(i)}=-1}[\\Sigma^{-1}x^{(i)}-\\Sigma^{-1}\\mu_{-1}] \\\\\n",
    "    &= \\sum_{i=1}^m1\\{y^{(i)}=-1\\}[\\Sigma^{-1}x^{(i)}-\\Sigma^{-1}\\mu_{-1}] \\\\\n",
    "    &= \\Sigma^{-1}\\sum_{i=1}^m1\\{y^{(i)}=-1\\}(x^{(i)}-\\mu_{-1}) \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Since $\\Sigma$ is invertible, then $\\Sigma^{-1}$ is invertible and the first equality follows:\n",
    "\n",
    "$$\\begin{align*} \n",
    "0 = \\sum_{i=1}^m1\\{y^{(i)}=-1\\}(x^{(i)}-\\mu_{-1}) = \\sum_{i=1}^m1\\{y^{(i)}=-1\\}x^{(i)}-\\sum_{i=1}^m1\\{y^{(i)}=-1\\}\\mu_{-1} \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Or\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\mu_{-1}\\sum_{i=1}^m1\\{y^{(i)}=-1\\} = \\sum_{i=1}^m1\\{y^{(i)}=-1\\}\\mu_{-1} = \\sum_{i=1}^m1\\{y^{(i)}=-1\\}x^{(i)}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Or\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\mu_{-1} = \\frac{\\sum_{i=1}^m1\\{y^{(i)}=-1\\}x^{(i)}}{\\sum_{i=1}^m1\\{y^{(i)}=-1\\}}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "The computation for $\\mu_1$ is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To find the maximum in $\\Sigma$, we will find the maximum in $S\\equiv\\Sigma^{-1}$. For intuition, define $f(x)=-(x-2)^2$ for $x\\in\\mathbb{R}$. We know that the maximum of $f(x)$ is at $x_0=2$. But if we find the maximum of $f\\big(\\frac{1}{\\alpha}\\big)$ over all $\\alpha\\in\\mathbb{R}$, then the maximum is at $\\alpha_0=\\frac{1}{2}=\\frac{1}{x_0}=x_0^{-1}$.\n",
    "\n",
    "Recall (from lin-alg-review-notes) that $\\lvert S\\rvert=\\lvert \\Sigma^{-1}\\rvert=\\frac{1}{\\lvert\\Sigma\\rvert}$. Then\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_S\\ell &= \\sum_{i=1}^m\\nabla_S\\big[\\frac{1}{2}\\mathrm{ln}\\frac{1}{\\lvert\\Sigma\\rvert}-\\frac{1}{2}(x^{(i)}-\\mu_{y^{(i)}})^T\\Sigma^{-1}(x^{(i)}-\\mu_{y^{(i)}})\\big] \\\\\n",
    "    &= \\sum_{i=1}^m\\nabla_S\\big[\\frac{1}{2}\\mathrm{ln}\\lvert S\\rvert-\\frac{1}{2}(x^{(i)}-\\mu_{y^{(i)}})^TS(x^{(i)}-\\mu_{y^{(i)}})\\big] \\\\\n",
    "    &= \\sum_{i=1}^m\\nabla_S\\big[\\frac{1}{2}\\mathrm{ln}\\lvert S\\rvert-\\frac{1}{2}b_i^TSb_i\\big] \\\\\n",
    "    &= \\sum_{i=1}^m\\big[\\frac{1}{2\\lvert S\\rvert}\\nabla_S\\lvert S\\rvert-\\frac{1}{2}\\nabla_Sb_i^TSb_i\\big] \\tag{4} \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "where we have defined $b_i\\equiv x^{(i)}-\\mu_{y^{(i)}}$. Then\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_S\\lvert S\\rvert=\\lvert S\\rvert(S^{-1})^T=\\lvert S\\rvert\\Sigma^T=\\lvert S\\rvert\\Sigma\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "The first equality follows from class-notes-1, p.9, eq.4 and the last equality follows because $\\Sigma$ is symmetric.\n",
    "\n",
    "Also note that\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\nabla_Sb_i^TSb_i=\\nabla_Str(b_i^TSb_i)=\\nabla_Str(Sb_ib_i^T)=(b_ib_i^T)^T=b_ib_i^T=(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\n",
    "\\end{align*}$$\n",
    "\n",
    "The first equality follows because $b_i^TSb_i\\in\\mathbb{R}$. The second equality follows because $b_i^TSb_i$ is a square matrix that is the product of a $1\\times n$ matrix ($b_i^T$) and a $n\\times1$ matrix ($Sb_i$). The trace operator commutes in this case. The third equality follows from class-notes-1, p.9, eq.1.\n",
    "\n",
    "Setting the gradient equal to zero, (4) becomes\n",
    "\n",
    "$$\\begin{align*} \n",
    "0=\\nabla_S\\ell &= \\sum_{i=1}^m\\big[\\frac{1}{2\\lvert S\\rvert}\\nabla_S\\lvert S\\rvert-\\frac{1}{2}\\nabla_Sb_i^TSb_i\\big] \\\\\n",
    "    &= \\sum_{i=1}^m\\big[\\frac{1}{2\\lvert S\\rvert}\\lvert S\\rvert\\Sigma-\\frac{1}{2}(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\\big]\\\\\n",
    "    &= \\sum_{i=1}^m\\big[\\frac{1}{2}\\Sigma-\\frac{1}{2}(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\\big]\n",
    "\\end{align*}$$\n",
    "\n",
    "Multiplying through by $2$, we get\n",
    "\n",
    "$$\\begin{align*} \n",
    "0 &= \\sum_{i=1}^m\\big[\\Sigma-(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\\big] \\\\\n",
    "     &= \\sum_{i=1}^m\\Sigma-\\sum_{i=1}^m\\big[(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\\big] \\\\\n",
    "     &= m\\Sigma-\\sum_{i=1}^m(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\n",
    "\\end{align*}$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\Sigma=\\frac{1}{m}\\sum_{i=1}^m(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although not required by the problem, I found it very helpful to plot the decision boundary for this problem using the data from problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(df_X)=<class 'pandas.core.frame.DataFrame'> and df_X.shape=(99, 2)\n",
      "And the head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343250</td>\n",
       "      <td>-1.331148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.820553</td>\n",
       "      <td>-0.634668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.986321</td>\n",
       "      <td>-1.888576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.343250 -1.331148\n",
       "1  1.820553 -0.634668\n",
       "2  0.986321 -1.888576"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = pd.read_csv('./logistic_x.txt', sep='\\ +', header=None, engine='python')\n",
    "print(\"type(df_X)={} and df_X.shape={}\".format(type(df_X),df_X.shape))\n",
    "print(\"And the head:\")\n",
    "df_X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(df_y)=<class 'pandas.core.frame.DataFrame'> and df_y.shape=(99, 1)\n",
      "And the head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0 -1\n",
       "1 -1\n",
       "2 -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.read_csv('./logistic_y.txt', sep='\\ +', header=None, engine='python')\n",
    "df_y = df_y.astype(int)\n",
    "print(\"type(df_y)={} and df_y.shape={}\".format(type(df_y),df_y.shape))\n",
    "print(\"And the head:\")\n",
    "df_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x115ef00f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUlIQEZEuJQUREen6f6X5TllTRyx5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115eb9630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's append the labels to the data\n",
    "df_X['label'] = df_y[0].values\n",
    "# And let's take a look at the two data points, called \"0\" and \"1\", for each observation, colored coded by label:\n",
    "ax = plt.axes()\n",
    "df_X.query('label == -1').plot.scatter(x=0, y=1, ax=ax, color='blue')\n",
    "df_X.query('label == 1').plot.scatter(x=0, y=1, ax=ax, color='red')\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X)=<class 'numpy.ndarray'>  X.shape=(99, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert X's to numpy array\n",
    "X = df_X[[0, 1]].values\n",
    "print(\"type(X)={}  X.shape={}\".format(type(X),X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y)=<class 'numpy.ndarray'>  y.shape=(99,)  number of ones=49  number of negative ones=-50\n"
     ]
    }
   ],
   "source": [
    "# convert y's to numpy array\n",
    "y = df_y.values.flatten()\n",
    "cntones=sum([y[i] if y[i]==1 else 0 for i in range(len(y))])\n",
    "cntnegones=sum([y[i] if y[i]==-1 else 0 for i in range(len(y))])\n",
    "print(\"type(y)={}  y.shape={}  number of ones={}  number of negative ones={}\"\n",
    "      .format(type(y),y.shape,cntones, cntnegones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our estimates for $\\mu_{-1}$ and $\\mu_1$:\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\mu_{-1} = \\frac{\\sum_{i=1}^m1\\{y^{(i)}=-1\\}x^{(i)}}{\\sum_{i=1}^m1\\{y^{(i)}=-1\\}}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\mu_{1} = \\frac{\\sum_{i=1}^m1\\{y^{(i)}=1\\}x^{(i)}}{\\sum_{i=1}^m1\\{y^{(i)}=1\\}}\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features=2\n",
      "mun1n=[ 146.53407208  -72.23823447]  mun1d=50\n",
      "mun1=[[ 2.93068144]\n",
      " [-1.44476469]]\n",
      "mu1n=[ 241.87216715   37.61822942]  mu1d=49\n",
      "mu1=[[ 4.93616668]\n",
      " [ 0.76771897]]\n"
     ]
    }
   ],
   "source": [
    "# let's compute the mean vectors\n",
    "num_features=X.shape[1]\n",
    "print(\"num_features={}\".format(num_features))\n",
    "\n",
    "mun1n=np.sum(X[y==-1],axis=0)\n",
    "mun1d=np.sum([y==-1])\n",
    "mun1=(mun1n/mun1d).reshape(num_features,1) # reshape to column vector (rather than array)\n",
    "print(\"mun1n={}  mun1d={}\\nmun1={}\".format(mun1n,mun1d,mun1))\n",
    "\n",
    "mu1n=np.sum(X[y==1],axis=0)\n",
    "mu1d=np.sum([y==1])\n",
    "mu1=(mu1n/mu1d).reshape(num_features,1)\n",
    "print(\"mu1n={}  mu1d={}\\nmu1={}\".format(mu1n,mu1d,mu1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our estimate for $\\Sigma$:\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\Sigma=\\frac{1}{m}\\sum_{i=1}^m(x^{(i)}-\\mu_{y^{(i)}})(x^{(i)}-\\mu_{y^{(i)}})^T\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=99  Sigma.shape=(2, 2)\n",
      "Sigma=[[ 2.68174521 -0.46404053]\n",
      " [-0.46404053  1.88367821]]\n"
     ]
    }
   ],
   "source": [
    "# let's compute Sigma\n",
    "m=X.shape[0]\n",
    "Sigma=np.zeros((num_features,num_features))\n",
    "for i in range(m):\n",
    "    # reshape to column vector so that .dot is 2x1 dot 1x2 = 2x2\n",
    "    # rather than 2, dot 2, = 1\n",
    "    xi = X[i,:].reshape(num_features,1)\n",
    "    muyi = mu1 if y[i]==1 else mun1 # this is already a column vector\n",
    "    # uncomment if you want to see some rows\n",
    "#    if np.mod(i,11)==0:\n",
    "#        print(\"i={}  xi={}  muyi={}\".format(i,xi,muyi))\n",
    "    Sigma += (xi-muyi).dot((xi-muyi).T)\n",
    "Sigma = 1/m * Sigma\n",
    "print(\"m={}  Sigma.shape={}\".format(m,Sigma.shape))\n",
    "print(\"Sigma={}\".format(Sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our estimate for $\\phi$:\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\phi = \\frac1m\\sum_{i=1}^m{1\\{y^{(i)}=1\\}}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi=0.494949494949495\n"
     ]
    }
   ],
   "source": [
    "phi=mu1d/m\n",
    "print(\"phi={}\".format(phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our definitions for $\\theta$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\theta &\\equiv \\Sigma^{-1}(\\mu_1-\\mu_{-1}) \\\\\n",
    "\\theta_0 &\\equiv \\frac{1}{2}\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_1^T\\Sigma^{-1}\\mu_1 - \\mathrm{ln}\\Big(\\frac{1 - \\phi}{\\phi}\\Big) \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta12=[ 0.99341623  1.41928119]\n",
      "theta0=-3.4472708878475564\n"
     ]
    }
   ],
   "source": [
    "S=np.linalg.inv(Sigma)\n",
    "theta12=S.dot(mu1-mun1).flatten()\n",
    "w1=mun1.T.dot(S.dot(mun1))\n",
    "w2=mu1.T.dot(S.dot(mu1))\n",
    "theta0=1/2*(w1-w2)[0,0]-np.log((1-phi)/phi)\n",
    "print(\"theta12={}\".format(theta12))\n",
    "print(\"theta0={}\".format(theta0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta=[-3.4472708878475564, 0.99341623197899342, 1.419281185004498]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiLS4v8D3mkmqrWxxcEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11605eb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def graph_ineff(funct, x_range, cl='r--', show=False):\n",
    "    y_range=[]                                                                                   \n",
    "    for x in x_range:\n",
    "        y_range.append(funct(x))\n",
    "    plt.plot(x_range,y_range,cl)\n",
    "    if show: plt.show()\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "df_X.query('label == -1').plot.scatter(x=0, y=1, ax=ax, color='blue')\n",
    "df_X.query('label == 1').plot.scatter(x=0, y=1, ax=ax, color='red')\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')\n",
    "\n",
    "theta=[theta0,theta12[0],theta12[1]]\n",
    "print(\"theta={}\".format(theta))\n",
    "graph_ineff(lambda x1: (theta[0] + theta[1] * x1) / (- theta[2]),np.linspace(0,8,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Outstanding questions: how do we know that $\\ell(\\phi,\\mu_{-1},\\mu_1,\\Sigma)$ is maximized in any of these parameters when taking the gradient? I guess $\\ell$ is concave in each of these parameters? I read somewhere that all distributions in the exponential family are concave (in which parameter?). And in the class notes, we saw that the Bernoulli and Gaussian (single-variable) distributions are both in the exponential family. So I guess $p(x|y)p(y)$ is in the exponential family?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
